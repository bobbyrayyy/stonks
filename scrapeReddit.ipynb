{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Reddit\n",
    "\n",
    "Our mini project was inspired by the rise of \"meme stocks\" like Gamestop and AMC, which were caused by retail investors rallying on this one particular Reddit thread named r/WallStreetBets. Hence, we wanted to scrape data from this particular thread, to see if the amount of activity on this thread would have a correlation with a stock's trade volume. Because more people talking about a stock = more people buying and selling that stock (or at least that's what we hypothesise). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRAW\n",
    "\n",
    "PRAW is an acronym for \"Python Reddit API Wrapper\", and it is a python package that allows for simple access to Reddit's API. After looking around for various options, PRAW seems like the best way to scrape data from Reddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in c:\\users\\ngjun\\anaconda3\\lib\\site-packages (7.1.4)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\ngjun\\anaconda3\\lib\\site-packages (from praw) (0.57.0)\n",
      "Requirement already satisfied: prawcore<2.0,>=1.5.0 in c:\\users\\ngjun\\anaconda3\\lib\\site-packages (from praw) (1.5.0)\n",
      "Requirement already satisfied: update-checker>=0.18 in c:\\users\\ngjun\\anaconda3\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\ngjun\\appdata\\roaming\\python\\python37\\site-packages (from prawcore<2.0,>=1.5.0->praw) (2.25.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ngjun\\appdata\\roaming\\python\\python37\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.5.0->praw) (2020.11.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\ngjun\\appdata\\roaming\\python\\python37\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.5.0->praw) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\ngjun\\appdata\\roaming\\python\\python37\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.5.0->praw) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ngjun\\appdata\\roaming\\python\\python37\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.5.0->praw) (1.26.2)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\ngjun\\appdata\\roaming\\python\\python37\\site-packages (from prawcore<2.0,>=1.5.0->praw) (2.25.0)\n",
      "Requirement already satisfied: six in c:\\users\\ngjun\\appdata\\roaming\\python\\python37\\site-packages (from websocket-client>=0.54.0->praw) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\ngjun\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Credentials to Use PRAW\n",
    "\n",
    "Credit to this tutorial for teaching us how to get our own credentials to start using PRAW:\n",
    "https://towardsdatascience.com/scraping-reddit-data-1c0af3040768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.1.4 of praw is outdated. Version 7.2.0 was released Wednesday February 24, 2021.\n"
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(client_id='BZPt6Wy_TiwRZA', client_secret='xafgjbf0l1wTQ0x3j8aq8_-RxdXBuA', user_agent='dsai stonks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Ranges\n",
    "\n",
    "We wanted to scrape Reddit across a range of dates, so we created a list that contained every date in this range.\n",
    "\n",
    "Only weekdays are included in this list, because the stock markets are closed on weekends! The function pandas.bdate_range() gives us a simple way to do this, as it returns all weekdays within a specified range.\n",
    "\n",
    "Our full set of data from Reddit spans from 22nd June 2018 to 14th April 2021. What you see in the cell below is just a subset of this, as we split up the scraping among the team. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-26\n",
      "2021-03-29\n",
      "2021-03-30\n",
      "2021-03-31\n",
      "2021-04-01\n",
      "2021-04-02\n",
      "2021-04-05\n",
      "2021-04-06\n",
      "2021-04-07\n",
      "2021-04-08\n",
      "2021-04-09\n"
     ]
    }
   ],
   "source": [
    "datelist = pd.bdate_range(start = datetime.date(2021, 3, 26), end = datetime.date(2021, 4, 9)).to_pydatetime().tolist()\n",
    "converted_datelist = []\n",
    "\n",
    "for item in datelist:\n",
    "    converted_datelist.append(item.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "for item in converted_datelist:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Scraping\n",
    "Time to start scraping some data from Reddit! \n",
    "\n",
    "### Thread Titles\n",
    "The subreddit \"r/WallStreetBets\" has a main discussion thread that is regulated, and the bulk of the activity happens here. We accessed this thread for each date in our desired range, and we did this by searching with the thread's title. However, it's important to note that the thread is titled differently for Fridays.\n",
    "\n",
    "Fridays: \"Weekend Discussion Thread for the Weekend of March 19, 2021\"\n",
    "\n",
    "Mon-Thurs: \"Daily Discussion Thread for February 08, 2021\"\n",
    "\n",
    "### Thread Comments\n",
    "For each day, we iterate through the comments on that day's discussion thread, and we basically count how many times a certain company or stock is mentioned. We did this for 10 companies: Apple, Microsoft, Costco, Tesla, Nio, Gamestop, AMC, Virgin Galactic, Tilray, Bed Bath and Beyond.\n",
    "\n",
    "### Choice of Stocks\n",
    "We intentionally chose a wide range of stocks to do our analysis on. We have some legit growth stocks that are popular on Reddit, such as AAPL and TSLA. We also have some meme stocks that are extremely popular on Reddit, like AMC and GME. Finally, we included some stocks that are less popular on Reddit, such as SPCE, TLRY, and BBBY. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekend Discussion Thread for the Weekend of March 26, 2021\n",
      "10252 2021-03-26 00:00:00\n",
      "Daily Discussion Thread for March 29, 2021\n",
      "9225 2021-03-29 00:00:00\n",
      "Daily Discussion Thread for March 30, 2021\n",
      "9102 2021-03-30 00:00:00\n",
      "Daily Discussion Thread for March 31, 2021\n",
      "8994 2021-03-31 00:00:00\n",
      "Daily Discussion Thread for April 01, 2021\n",
      "9164 2021-04-01 00:00:00\n",
      "0 2021-04-02 00:00:00\n",
      "Daily Discussion Thread for April 05, 2021\n",
      "9062 2021-04-05 00:00:00\n",
      "Daily Discussion Thread for April 06, 2021\n",
      "7912 2021-04-06 00:00:00\n",
      "Daily Discussion Thread for April 07, 2021\n",
      "8301 2021-04-07 00:00:00\n",
      "Daily Discussion Thread for April 08, 2021\n",
      "8258 2021-04-08 00:00:00\n",
      "Weekend Discussion Thread for the Weekend of April 09, 2021\n",
      "9424 2021-04-09 00:00:00\n"
     ]
    }
   ],
   "source": [
    "apple_list = []\n",
    "microsoft_list = []\n",
    "costco_list = []\n",
    "tesla_list = []\n",
    "nio_list = []\n",
    "gme_list = []\n",
    "amc_list = []\n",
    "spce_list = []\n",
    "tlry_list = []\n",
    "bbby_list = []\n",
    "\n",
    "for item in datelist:\n",
    "    string = None\n",
    "    if item.strftime(\"%a\") == \"Fri\":\n",
    "        string = \"Weekend Discussion Thread for the Weekend of \" + item.strftime(\"%B %d, %Y\")\n",
    "    else:\n",
    "        string = \"Daily Discussion Thread for \" + item.strftime(\"%B %d, %Y\")\n",
    "    \n",
    "    comment_list = []\n",
    "    submission = reddit.subreddit('WallStreetBets').search(string, sort = \"relevance\", limit = 1)\n",
    "    for post in submission:\n",
    "        print(post.title)\n",
    "        post.comments.replace_more(limit=100)\n",
    "        for comment in post.comments.list():\n",
    "            comment_list.append(comment.body.lower())\n",
    "\n",
    "    print(len(comment_list), item)\n",
    "    \n",
    "    apple = 0\n",
    "    microsoft = 0\n",
    "    costco = 0\n",
    "    tesla = 0\n",
    "    nio = 0\n",
    "    gamestop = 0\n",
    "    amc = 0\n",
    "    spce = 0\n",
    "    tlry = 0\n",
    "    bbby = 0\n",
    "    for string in comment_list:\n",
    "        if (\"apple\" in string) or (\"aapl\" in string):\n",
    "            apple += 1\n",
    "        if (\"msft\" in string) or (\"microsoft\" in string):\n",
    "            microsoft += 1\n",
    "        if (\"costco\" in string) or (\"cost\" in string):\n",
    "            costco += 1\n",
    "        if (\"tsla\" in string) or (\"tesla\" in string):\n",
    "            tesla += 1\n",
    "        if (\"nio\" in string):\n",
    "            nio += 1\n",
    "        if (\"gme\" in string) or (\"gamestop\" in string):\n",
    "            gamestop += 1\n",
    "        if (\"amc\" in string):\n",
    "            amc += 1\n",
    "        if (\"spce\" in string) or (\"virgin\" in string):\n",
    "            spce += 1\n",
    "        if (\"tlry\" in string) or (\"tilray\" in string):\n",
    "            tlry += 1\n",
    "        if (\"bbby\" in string) or (\"bed\" in string) or (\"bath\" in string):\n",
    "            bbby += 1\n",
    "            \n",
    "    apple_list.append(apple)\n",
    "    microsoft_list.append(microsoft)\n",
    "    costco_list.append(costco)\n",
    "    tesla_list.append(tesla)\n",
    "    nio_list.append(nio)\n",
    "    gme_list.append(gamestop)\n",
    "    amc_list.append(amc)\n",
    "    spce_list.append(spce)\n",
    "    tlry_list.append(tlry)\n",
    "    bbby_list.append(bbby)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting to CSV\n",
    "\n",
    "This final portion of code is just to convert our stored results into a csv file, which we will use in our next notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(list(zip(converted_datelist, apple_list, microsoft_list, costco_list, tesla_list, nio_list, gme_list, amc_list, spce_list, tlry_list, bbby_list)),\n",
    "                 columns = ['Date', 'Apple', 'Microsoft', 'Costco', 'Tesla', 'Nio', 'Gamestop', 'AMC', 'Virgin Galactic', 'Tilray', 'Bed Bath & Beyond'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Here are the some of the results. As explained earlier, this is just a subset of our final dataset, which is much larger. The number in each cell basically represents how many times that particular company/stock was mentioned in the Reddit thread on that day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Apple</th>\n",
       "      <th>Microsoft</th>\n",
       "      <th>Costco</th>\n",
       "      <th>Tesla</th>\n",
       "      <th>Nio</th>\n",
       "      <th>Gamestop</th>\n",
       "      <th>AMC</th>\n",
       "      <th>Virgin Galactic</th>\n",
       "      <th>Tilray</th>\n",
       "      <th>Bed Bath &amp; Beyond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>80</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>178</td>\n",
       "      <td>110</td>\n",
       "      <td>442</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>119</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>292</td>\n",
       "      <td>93</td>\n",
       "      <td>257</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>169</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>482</td>\n",
       "      <td>119</td>\n",
       "      <td>394</td>\n",
       "      <td>99</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>169</td>\n",
       "      <td>95</td>\n",
       "      <td>16</td>\n",
       "      <td>425</td>\n",
       "      <td>152</td>\n",
       "      <td>239</td>\n",
       "      <td>91</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>116</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>806</td>\n",
       "      <td>219</td>\n",
       "      <td>172</td>\n",
       "      <td>293</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-04-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>142</td>\n",
       "      <td>46</td>\n",
       "      <td>30</td>\n",
       "      <td>667</td>\n",
       "      <td>84</td>\n",
       "      <td>658</td>\n",
       "      <td>275</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>114</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>315</td>\n",
       "      <td>78</td>\n",
       "      <td>199</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>141</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>351</td>\n",
       "      <td>148</td>\n",
       "      <td>179</td>\n",
       "      <td>74</td>\n",
       "      <td>14</td>\n",
       "      <td>71</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>313</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>73</td>\n",
       "      <td>383</td>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "      <td>83</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-04-09</td>\n",
       "      <td>157</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>142</td>\n",
       "      <td>60</td>\n",
       "      <td>424</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>44</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Apple  Microsoft  Costco  Tesla  Nio  Gamestop  AMC  \\\n",
       "0   2021-03-26     80         19      49    178  110       442   60   \n",
       "1   2021-03-29    119         10      27    292   93       257   72   \n",
       "2   2021-03-30    169         16      28    482  119       394   99   \n",
       "3   2021-03-31    169         95      16    425  152       239   91   \n",
       "4   2021-04-01    116         34      23    806  219       172  293   \n",
       "5   2021-04-02      0          0       0      0    0         0    0   \n",
       "6   2021-04-05    142         46      30    667   84       658  275   \n",
       "7   2021-04-06    114         28      20    315   78       199   99   \n",
       "8   2021-04-07    141         29      20    351  148       179   74   \n",
       "9   2021-04-08    313         33      30    250   73       383   66   \n",
       "10  2021-04-09    157         30      31    142   60       424   25   \n",
       "\n",
       "    Virgin Galactic  Tilray  Bed Bath & Beyond  \n",
       "0                14      11                 41  \n",
       "1                18       7                 26  \n",
       "2                13      19                 26  \n",
       "3                 6      67                 36  \n",
       "4                 6      21                 22  \n",
       "5                 0       0                  0  \n",
       "6                22      35                 20  \n",
       "7                 9      32                 33  \n",
       "8                14      71                 27  \n",
       "9                10      83                 25  \n",
       "10               19      44                 63  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"darren4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Comments\n",
    "\n",
    "Unfortunately, there were some anomalies in the data. If you look at row 5, there is a whole row of zeroes. On some days, the discussion thread is missing from r/WallStreetBets, probably because they have been archived. There's nothing much we can do about that except to delete row 5. Hence, you might notice some missing dates in our final dataset.\n",
    "\n",
    "After cleaning up the anomalies and compiling all our data into one large csv named \"scrappedData.csv\", we used it together with data from the Alpha Vantage API. **On to the next notebook!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
